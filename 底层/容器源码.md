## hashmap，concurrenthashmap底层实现，put流程, 以及扩容方法

https://www.pdai.tech/md/java/collection/java-collection-ArrayList.html



## Fail Fast Iterators
当容器存在一个structural modification的时候（当有一个线程在遍历这个容器是，这个容器要增加或者删除一个元素）
立即throw抛出一个concurrentModificationException异常。

因为他们是在原始集合上进行更改的

> arrayList, hashMap是一个例子

通过对源码的学习：
```java
// 是否会抛出并发异常其实就在看modCount和expeoctedModCount是否相同。对集合的修改就会改变modCount的值。

// 不能对asList生成的ArrayList进行修改，底层直接用final修饰的数组。

```

> 避免方法：remove使用迭代器的remove而不是集合的remove；也可以对iterator对象加锁，或者ConpyOnWriteArrayList

## Fail Safe Iterators
当容器存在一个structural modification的时候（当有一个线程在遍历这个容器时，某线程需要对这个容器增加或者删除一个元素）。单线程多线程都会抛出这个异常。

不会throw抛出一个concurrentModificationException异常。因为他们是在容器的clone上进行操作的, 写完之后再将原容器的引用指向新容器。

希望写入的数据不一定能马上读到，不能保证实时的一致性。

>ConcurrentHashMap是一个例子

## ArrayList
数组

## LinkedList

双向链表，存有两个指针，last and first。
LinkedList可以实现List接口、Deque接口、也可以看做Queue接口、Stack接口。
>并发的方法：Collections.synchronizedList()方法

## ArrayDeque
循环数组。因为要在一个数组里循环，所以越界了就需要取余。

deque是双向链表。需要在头尾插入or删除节点。
不能有null
线程不安全

    head, tail分别指向数组的起点和下一个可以插入的空位，但是head不一定比tial大。
    insert: elements[--head] = e or element[tail++] = e.

> 扩容：doubleCapacity: 分两次扩容，一次是head右边的元素，另一次是复制head左边的元素

## priorityQueue 堆来实现

完全二叉树来实现小顶堆（任意一个非叶子结点的权值都不大于左右子节点的权值。）

可以通过数组来作为PriorityQueue的底层实现。




## hashMap

#### 1.7-1.8的hash函数变了

1.7: h&(n-1)
1.8: 高位和地位异或，保留高位信息，加大随机性，均匀分散冲突
```java
static final int hash(Object key) {
    int h;
    // 混合原始哈希码的高位和低位，以此来加大低位的随机性。这样高位信息也别保留了。可以均匀的把之前的冲突的节点分散到新的bucket
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

#### 扩容机制 put() & resize()：

初始化`DEFAULT_INITIAL_CAPACITY=16`，最大是`1<<30`
threshad = capacity*load_factor

jdk1.7

hashMap中的一些参数：
`public HashMap(int initialCapacity(数组大小), float loadFactor（装载因子，扩容阈值) = 0.75 ;`
`初始化容量：16:1<<4`

当map中包含的Node的数量（size) 大于等于threshold = loadFactor * capacity(桶的长度）的时候，且新建的Entry刚好落在一个非空的桶上，此刻触发扩容机制，将其容量扩大为*2倍*。

p.s.: 当size大于等于threshold的时候，并不一定会触发扩容机制.只要有一个新建的Node出现哈希冲突，则立刻resize。

resize时候需要完成新表到旧表的转移（transfer）：遍历旧表中的每个桶节点。这个桶节点就是对应数组index位置的链表的头节点。然后依次使用next的方法遍历这些链表，找到每个节点在新表中对应的新位置并插入。*因此多线程时hashMap是不安全的。因为当多个线程同时transfer, 某个线程t所持有的引用next，也就是下一个需要被转移的节点，可能已经放在新表里了。会出现多个线程对同一链表无限进行链表transfer的操作，极易造成死循环，数据丢失等等*

为什么容量必须是二的n次幂：因为获取对应位置时候，是将哈希值h与桶数组的length-1（全1）进行了一个与操作得出了对应的桶的位置，因此如果不是2的倍数，那len-1就不是全1的。

(1.7使用的是头插法，永远添加到数组的头部位置)


1.8:
```java
    put方法:
    1. 第一次put,触发resize(),初始化长度为16
    2. 找到数组下标，如果该位置没有值，则直接初始化Node
    2. 如果有值，判断这第一个值是否是key。如果不是则进行差值（判断是TreeNode, 还是Node，链表还是红黑树）
        2.1 如果是链表，待插入的值如果是第8个，则会触发treeifyBin, 将链表变成红黑树。（先插入，后变红黑树）
    3. 判断如果当前size > threshold，则需要扩容。

    resize方法：
    1. 如果是第一次resize, 当前数组还没有值，则初始化大小为16, 更新阈值为16*load_factor
    2. 将数组大小*2。阈值*2.
    3. 创建一个新的数组，遍历原数组进行数据迁移。
        3.1 如果这个下标对应的value只有一个元素就简单迁移
        3.2 如果对应的是一个红黑树，则TreeNode<K, V>e.split
        3.3 如果是一个链表，则将此链表拆成两个`if ((e.hash & oldCap) == 0) `，放到新的数组中。lo链表就是直接放到新数组的这个位置，hi链表放到[当前index+oldCap]的位置。
        （拆成两个： 是根据扩容后，这个节点对应地址的值是否是改变得到的。因为地址其实就是hash值与容器容量取余数，那么容量变大后，就只有两种可能，要么变成二倍，要么不改变。）
        
```

> 总结：java8 相比java7来讲，优化的点：
> java7:先扩容后插值，1.8先插值再判断是否需要扩容。
> java7的hash值计算方法是直接相与，而8的是将前部分与后部分异或，保留了高位信息，均匀分配。
> java7节点插入是头插入，8是尾插入
> java7没有用到红黑树，8用到了，而且是先插入，判断当前地址对应的node是连标的node还是TreeNode，采用不同方法。

## linkedHashMap

extends继承自hashMap，在此基础上加了一个双链表。保证插入顺序。

改变方法：将Entry本身改了, 增加了before, after。因此进行hashcode，equals时
```java
static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```
这个双链表，将所有的entry链接起来。因此，迭代的时候，只用迭代双向链表即可，不用遍历整个table。

非同步。同步的方法：`Collections.synchronizedMap(new LinkedHashMap(...))`

> 使用环境：FIFO的缓存

## ConcurrentHashMap
线程安全。CAS+volatile

Node节点和TreeNode(继承自linkedHashMap.Entry)

 ### 和hashTable区别
 hashtable是用synchronized, 效率低。线程1put时，线程2无法put or get

> volatile是轻量级的同步机制。具备三层语义：可见行、原子性、有序性

> CAS一般被理解为原子操作。

每个节点Node存储四个变量
```java
final int hash;
final K key;
volatile V val; // 保持可变性
volatile Node<K,V> next;
```
**(未完待续)**

[参考链接](https://blog.nowcoder.net/n/300401e7ae5c4da4acdc6aff0408274a)